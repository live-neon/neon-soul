# Plan: NEON-SOUL End-to-End Testing

**Date**: 2026-02-09
**Status**: In Progress (Stage 5 pending)
**Project**: projects/live-neon/neon-soul
**Trigger**: think hard

---

## Summary

Systematically test neon-soul end-to-end against a real (or realistic) environment to find what's broken before production use. Focus on actual file I/O, state persistence, and real-world scenarios rather than just mock-based unit tests.

**Goal**: Find failures, document them, fix what's critical.

**Result**: 175 tests passing (including 21 real LLM tests). Found and fixed 3 issues + 11 code review items. OpenClaw integration (Stage 5) pending.

See:
- [e2e-testing-findings.md](../issues/e2e-testing-findings.md)
- [e2e-testing-code-review-findings.md](../issues/e2e-testing-code-review-findings.md)
- [2026-02-08-ollama-llm-provider.md](./2026-02-08-ollama-llm-provider.md)

---

## Files Created/Modified

- `tests/e2e/real-environment.test.ts` (new) - Real file I/O tests
- `tests/e2e/state-persistence.test.ts` (new) - Multi-run tests
- `tests/e2e/safety-rails.test.ts` (new) - Security/safety tests
- `docs/issues/e2e-testing-findings.md` (new) - Document failures

---

## Context

### Current State
- 143 unit/integration tests passing
- 23 E2E tests in `live-synthesis.test.ts` (481 lines)
- Mock LLM used throughout (deterministic, fast)
- Docker setup exists but not tested

### Gaps Identified
1. **File I/O verification** - Tests check data structures, not actual disk writes
2. **State persistence** - Only single-run tested; no multi-run verification
3. **Format variations** - Only 'notated' tested; 'native' not verified
4. **Safety rails** - Symlink protection (I-4 FIX) not tested
5. **Real LLM** - Semantic behavior untested
6. **Provenance accuracy** - Signal→principle→axiom chain not verified end-to-end

---

## Stages

### Stage 0: Setup Test Environment

**Purpose**: Establish realistic test workspace with actual memory files

**Tasks**:
1. Create `tests/e2e/fixtures/realistic-memory/` with 5-10 actual memory MD files
2. Each file should have signals matching different dimensions
3. Include edge cases: empty file, non-UTF8 content, symlink (for security test)
4. Create test harness that copies fixtures to temp workspace

**Acceptance Criteria**:
- [x] Fixtures exist with representative content
- [x] Test harness creates/cleans temp workspace
- [x] All existing tests still pass

**Commit**: `test(neon-soul): add realistic E2E test fixtures`

---

### Stage 1: File I/O Verification Tests

**File**: `tests/e2e/real-environment.test.ts`

**Purpose**: Verify actual files are written correctly

**Test Cases**:
1. `synthesize writes SOUL.md to correct path`
   - Run synthesis with --force
   - Read SOUL.md from disk
   - Verify it contains expected sections (not empty, has axioms)

2. `synthesize creates .neon-soul directory structure`
   - Run synthesis
   - Verify .neon-soul/ exists with: state.json, signals.json, principles.json, axioms.json

3. `synthesize creates backup before overwrite`
   - Create initial SOUL.md
   - Run synthesis
   - Verify .neon-soul/backups/ contains previous version

4. `dry-run does not modify any files`
   - Record all file mtimes
   - Run synthesis with --dry-run
   - Verify no mtimes changed

5. `native format output differs from notated`
   - Run synthesis with --format native
   - Run synthesis with --format notated
   - Verify output differs (no CJK in native)

**Acceptance Criteria**:
- [x] All 5 tests pass or failures documented
- [x] File contents verified (not just existence)

**Commit**: `test(neon-soul): add file I/O verification E2E tests`

---

### Stage 2: State Persistence Tests

**File**: `tests/e2e/state-persistence.test.ts`

**Purpose**: Verify state persists correctly across runs

**Test Cases**:
1. `status reflects last synthesis run`
   - Run synthesis
   - Run status
   - Verify lastRun timestamp matches

2. `second synthesis builds on first`
   - Run synthesis (creates N axioms)
   - Add new memory file
   - Run synthesis again
   - Verify axiom count increased (or at least didn't reset)

3. `signals accumulate across runs`
   - Run synthesis
   - Check signal count
   - Add memory file with new signals
   - Run synthesis
   - Verify signal count increased

4. `rollback restores previous state`
   - Run synthesis (version A)
   - Modify memory, run synthesis (version B)
   - Run rollback --force
   - Verify SOUL.md matches version A content

5. `audit shows correct provenance after multi-run`
   - Run synthesis
   - Pick an axiom, trace it
   - Verify source file:line exists and contains expected text

**Acceptance Criteria**:
- [x] All 6 tests pass (added extra test for --force)
- [x] State persistence verified across restarts

**Commit**: `test(neon-soul): add state persistence E2E tests`

---

### Stage 3: Safety Rails Tests

**File**: `tests/e2e/safety-rails.test.ts`

**Purpose**: Verify security and safety mechanisms work

**Test Cases**:
1. `status rejects workspace with symlinks` (I-4 FIX)
   - Create workspace with symlink in memory/
   - Run status
   - Verify error or warning about symlink

2. `synthesize requires --force for production run`
   - Run synthesize without --force
   - Verify it doesn't write (or requires confirmation)

3. `rollback requires --force to execute`
   - Run rollback without --force
   - Verify no files changed
   - Run rollback --force
   - Verify restore happened

4. `atomic write survives interruption` (best effort)
   - Check that writeFileAtomic uses temp file + rename pattern
   - Verify no partial writes possible

5. `LLM required error when context missing`
   - Call synthesize without LLM provider
   - Verify LLMRequiredError thrown

**Acceptance Criteria**:
- [x] All 6 tests pass (added dry-run safety test)
- [x] Safety mechanisms verified

**Commit**: `test(neon-soul): add safety rails E2E tests`

---

### Stage 4: Real LLM Testing (Ollama) ✅ COMPLETE

**Purpose**: Test with real LLM for semantic validation

**Implementation**: See [2026-02-08-ollama-llm-provider.md](./2026-02-08-ollama-llm-provider.md)

**Files Created**:
- `src/lib/llm-providers/ollama-provider.ts` - OllamaLLMProvider
- `tests/e2e/ollama-provider.test.ts` - Provider tests
- `tests/e2e/real-llm.test.ts` - Real LLM E2E tests
- `docker/docker-compose.ollama.yml` - Ollama container

**Usage**:
```bash
docker compose -f docker/docker-compose.ollama.yml up -d
docker exec neon-soul-ollama ollama pull llama3
USE_REAL_LLM=true npm test tests/e2e/real-llm.test.ts
```

**Acceptance Criteria**:
- [x] OllamaLLMProvider implements LLMProvider interface
- [x] Tests skip gracefully when Ollama not available
- [x] Full synthesis pipeline works with real LLM

---

### Stage 5: OpenClaw Integration (Future)

**Status**: Pending - Final deployment validation

**Purpose**: Test neon-soul as a skill running inside OpenClaw

**Prerequisites**:
- Docker installed and running
- API keys configured (Anthropic or OpenAI)
- OpenClaw container healthy

**Setup**:
```bash
# 1. Configure API keys
cp docker/.env.example docker/.env
# Edit docker/.env with ANTHROPIC_API_KEY or OPENAI_API_KEY

# 2. Start OpenClaw
docker compose up -d

# 3. Verify health
curl http://localhost:8080/health
```

**Test Cases**:

1. **Skill Loader Integration**
   - Verify neon-soul skill is discovered by OpenClaw
   - Check skill manifest is valid
   - Confirm skill appears in `/skills` list

2. **LLM Context Forwarding**
   - OpenClaw provides LLM via skill context
   - Verify `context.llm` is passed to commands
   - Test that synthesis uses OpenClaw's LLM (not local)

3. **Command Accessibility**
   - `/neon-soul synthesize` triggers synthesis
   - `/neon-soul status` returns current state
   - `/neon-soul audit <axiom-id>` traces provenance
   - `/neon-soul rollback --force` restores previous version

4. **Error Handling**
   - Skill returns structured errors to OpenClaw
   - OpenClaw displays user-friendly messages
   - LLMRequiredError handled gracefully

5. **End-to-End Flow**
   - User adds memory content via OpenClaw
   - User runs `/neon-soul synthesize --force`
   - SOUL.md is generated and visible
   - User can query and audit axioms

**File**: `tests/e2e/openclaw-integration.test.ts` (to be created)

**Acceptance Criteria**:
- [ ] OpenClaw container starts and is healthy
- [ ] Skill loads without errors
- [ ] All 5 test cases pass
- [ ] Error messages are user-friendly

**Commit**: `test(neon-soul): add OpenClaw integration tests`

**Note**: This stage validates the "last mile" - that neon-soul works correctly when deployed inside OpenClaw. It requires API keys and is intended for pre-production validation, not CI.

---

### Stage 6: Document Findings ✅ COMPLETE

**File**: `docs/issues/e2e-testing-findings.md`

**Purpose**: Document all failures found during testing

**Structure**:
```markdown
# E2E Testing Findings

## Summary
- Tests run: X
- Passed: Y
- Failed: Z

## Failures

### F-1: [Title]
**Test**: [test name]
**Expected**: [what should happen]
**Actual**: [what happened]
**Severity**: critical/important/minor
**Fix**: [proposed fix or "needs investigation"]
```

**Acceptance Criteria**:
- [x] All failures documented with severity
- [x] Findings file created at `docs/issues/e2e-testing-findings.md`

**Commit**: `docs(neon-soul): document E2E testing findings`

---

## Verification

1. All new tests run: `npm test tests/e2e/real-environment.test.ts tests/e2e/state-persistence.test.ts tests/e2e/safety-rails.test.ts`
2. Existing tests still pass: `npm test`
3. Findings documented in issues file
4. README updated with test status

---

## Rollback Plan

If testing reveals critical issues:
1. Document in findings file
2. Create separate issue for each critical finding
3. Prioritize fixes before production use
4. Re-run E2E tests after fixes

---

## Cross-References

- **Findings**: [e2e-testing-findings.md](../issues/e2e-testing-findings.md)
- **Code Review (N=2)**: [e2e-testing-code-review-findings.md](../issues/e2e-testing-code-review-findings.md)
- **Real LLM Testing**: [2026-02-08-ollama-llm-provider.md](./2026-02-08-ollama-llm-provider.md) (extends Gap #5)
- **Master Plan**: [2026-02-07-soul-bootstrap-master.md](./2026-02-07-soul-bootstrap-master.md)
- **Proposal**: [soul-bootstrap-pipeline-proposal.md](../proposals/soul-bootstrap-pipeline-proposal.md)
- **Existing E2E**: `tests/e2e/live-synthesis.test.ts`
- **Test Fixtures**: `tests/e2e/fixtures/`
- **Docker Setup**: `docker/docker-compose.yml`

---

## Effort Estimate

- Stage 0: 30 min (fixtures setup) ✅
- Stage 1: 60 min (file I/O tests) ✅
- Stage 2: 60 min (state persistence tests) ✅
- Stage 3: 45 min (safety rails tests) ✅
- Stage 4: 120 min (real LLM testing with Ollama) ✅
- Stage 5: 90 min (OpenClaw integration) - Pending
- Stage 6: 30 min (documentation) ✅

**Completed**: ~5.5 hours
**Remaining**: ~1.5 hours (Stage 5: OpenClaw integration)

---

## Testing Strategy

**Approach**: Write tests that find failures, not tests that confirm success.

Each test should:
1. Set up realistic preconditions
2. Run the actual command (not mocked pipeline)
3. Verify actual file system state
4. Document any failures found

**Mock LLM**: Continue using mock LLM for determinism. Real LLM testing is separate scope.
